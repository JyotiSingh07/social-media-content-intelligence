{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import joblib, json, os\n",
    "\n",
    "\n",
    "# Paths\n",
    "EMB = 'outputs/image_embeddings_clean.csv'\n",
    "LABELS = 'outputs/moderation_labels.csv'\n",
    "OUT_JSON = 'outputs/moderation.json'\n",
    "MODEL_OUT = 'models/moderation_model_improved.pkl'\n",
    "\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "\n",
    "# Cell 2: load data\n",
    "emb = pd.read_csv(EMB)\n",
    "labels = pd.read_csv(LABELS)\n",
    "df = emb.merge(labels, on='filename', how='left')\n",
    "df['label'] = df['label'].fillna(0).astype(int)\n",
    "X = df.drop(columns=['filename','label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "\n",
    "# Cell 3: preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_s = scaler.fit_transform(X)\n",
    "# PCA for stability\n",
    "n_comp = min(100, X_s.shape[1], X_s.shape[0]-1)\n",
    "pca = PCA(n_components=n_comp, random_state=42)\n",
    "X_p = pca.fit_transform(X_s)\n",
    "\n",
    "\n",
    "# Cell 4: train/test split\n",
    "Xtr, Xte, ytr, yte, fn_tr, fn_te = train_test_split(X_p, y, df['filename'], test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# Cell 5: train models\n",
    "clf = LogisticRegression(max_iter=5000, class_weight='balanced', solver='saga')\n",
    "clf.fit(Xtr, ytr)\n",
    "rfc = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rfc.fit(Xtr, ytr)\n",
    "\n",
    "\n",
    "# Cell 6: evaluate\n",
    "proba_lr = clf.predict_proba(Xte)[:,1]\n",
    "proba_rf = rfc.predict_proba(Xte)[:,1]\n",
    "auc_lr = roc_auc_score(yte, proba_lr) if len(set(yte))>1 else None\n",
    "auc_rf = roc_auc_score(yte, proba_rf) if len(set(yte))>1 else None\n",
    "print('AUC LR:', auc_lr, 'AUC RF:', auc_rf)\n",
    "from sklearn.metrics import classification_report\n",
    "print('LR report:\\n', classification_report(yte, (proba_lr>=0.5).astype(int)))\n",
    "print('RF report:\\n', classification_report(yte, (proba_rf>=0.5).astype(int)))\n",
    "\n",
    "\n",
    "# Cell 7: choose and save best model (by AUC)\n",
    "chosen = clf if (auc_lr or 0) >= (auc_rf or 0) else rfc\n",
    "joblib.dump({'model': chosen, 'scaler': scaler, 'pca': pca}, MODEL_OUT)\n",
    "print('Saved model to', MODEL_OUT)\n",
    "\n",
    "\n",
    "# Cell 8: produce outputs/moderation.json for all files\n",
    "probs = chosen.predict_proba(pca.transform(scaler.transform(X)))[:,1]\n",
    "preds = (probs >= 0.5).astype(int)\n",
    "out = {fname: {'moderation': 'unsafe' if int(p)==1 else 'safe', 'prob_unsafe': float(pr)} for fname,p,pr in zip(df['filename'], preds, probs)}\n",
    "with open(OUT_JSON,'w') as f:\n",
    "json.dump(out, f, indent=2)\n",
    "print('Saved', OUT_JSON)\n",
    "\n",
    "\n",
    "# Cell 9: show some worst/best examples (optional)\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "sample_unsafe = [k for k,v in out.items() if v['moderation']=='unsafe'][:8]\n",
    "print('Sample unsafe:', sample_unsafe)\n",
    "for fn in sample_unsafe[:8]:\n",
    "img = Image.open('datasets/images/' + fn)\n",
    "plt.figure(figsize=(3,3)); plt.imshow(img); plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
